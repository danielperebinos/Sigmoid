{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789ababe-3d9a-4147-b488-bbaa81e9056b",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0baf6-6f29-4f4d-a6f1-9f3e8b4b6d2a",
   "metadata": {},
   "source": [
    "### Pytorch Realisation of Linear Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3392fe-134e-459e-b114-6fbe3457237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, functional as F\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26861fc6-9716-43e5-8dd0-1384f7eb18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(Linear):\n",
    "    def __init__(self, in_features, out_features = 1, bias = True):\n",
    "        super().__init__(in_features= in_features, out_features=out_features, bias=bias)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.00005)\n",
    "    \n",
    "    def fit(self, train_dl, num_epochs=100):\n",
    "        for epoch in range(num_epochs+1):\n",
    "            for x_batch, y_batch in train_dl:\n",
    "                self.prediction = self(x_batch.float())\n",
    "                loss = F.mse_loss(self.prediction, y_batch.float())\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dba0d8-83d0-4d18-9c17-9e5489ce32cb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Test on Boston Houses Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d46f44-b5c8-4462-8998-f4f7eae56e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41821e9f-a18a-4628-9704-37ee2a379749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.98765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.980</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0980</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>23.0</td>\n",
       "      <td>396.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.23456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.980</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.6540</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>23.0</td>\n",
       "      <td>343.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.44433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.123</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>23.0</td>\n",
       "      <td>343.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.77763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.222</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.5430</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>23.0</td>\n",
       "      <td>343.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.65432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.760</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>3</td>\n",
       "      <td>345</td>\n",
       "      <td>23.0</td>\n",
       "      <td>321.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "506  0.98765   0.0  12.50     0  0.561  6.980  89.0  2.0980    3  320   \n",
       "507  0.23456   0.0  12.50     0  0.561  6.980  76.0  2.6540    3  320   \n",
       "508  0.44433   0.0  12.50     0  0.561  6.123  98.0  2.9870    3  320   \n",
       "509  0.77763   0.0  12.70     0  0.561  6.222  34.0  2.5430    3  329   \n",
       "510  0.65432   0.0  12.80     0  0.561  6.760  67.0  2.9870    3  345   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "506     23.0  396.00  12.00  12.0  \n",
       "507     23.0  343.00  25.00  32.0  \n",
       "508     23.0  343.00  21.00  54.0  \n",
       "509     23.0  343.00  76.00  67.0  \n",
       "510     23.0  321.00  45.00  24.0  \n",
       "\n",
       "[511 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3f2dc8-d539-4a0b-ae25-91331f59594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isna().sum().sum() > 0:\n",
    "    df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6340d435-0b32-4e44-b1bf-51651ee07272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b4a61c-1f9d-4e2a-92d3-a987efd41b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]].values\n",
    "y = df[df.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea70701-2da2-4561-ab33-950d0755ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = torch.from_numpy(X)\n",
    "y_ = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf285b1-25d2-4173-9f19-f5c9fb8d380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tensor_dataset = TensorDataset(X_, y_)\n",
    "data_loader = DataLoader(tensor_dataset, batch_size=5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6db219-e4a8-4543-b26e-9f82a63d2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LinearRegression(13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fbfed21-7503-460a-affe-2cfd7716a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py:156: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 6050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 14676.40625\n",
      "Epoch 10, Loss: 7627.32861328125\n",
      "Epoch 20, Loss: 6046.310546875\n",
      "Epoch 30, Loss: 2830.946044921875\n",
      "Epoch 40, Loss: 1727.21337890625\n",
      "Epoch 50, Loss: 59.443145751953125\n",
      "Epoch 60, Loss: 93.16427612304688\n",
      "Epoch 70, Loss: 9.024128913879395\n",
      "Epoch 80, Loss: 104.44635772705078\n",
      "Epoch 90, Loss: 124.3644790649414\n",
      "Epoch 100, Loss: 49.80086135864258\n"
     ]
    }
   ],
   "source": [
    "l.fit(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1ec29-94af-4d18-ada5-b5af01b3c17f",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### Numpy Realisation of Linear Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca746d4c-684d-4bef-b5c1-8afc435a4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression_numpy():\n",
    "    def __init__(self, in_features, out_features, bias = True):\n",
    "        self.weight = np.random.rand(in_features, out_features)\n",
    "        self.bias = np.random.rand(out_features)\n",
    "    \n",
    "    def __loss_fn(self, y_predicted, target):\n",
    "        return np.square(y_predicted - target)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.matmul(X, self.weight) + self.bias\n",
    "    \n",
    "    def fit(self, X, y, num_epochs, lr):\n",
    "        mean_loss = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            for index in range(len(X)):\n",
    "                x_value, y_value = X[index], y[index]\n",
    "                loss = self.__loss_fn(self.predict(x_value), y_value) \n",
    "                mean_loss += loss\n",
    "                \n",
    "                direction = 2 * (self.predict(x_value) - y_value) \n",
    "                self.weight -= lr * (direction * x_value.transpose()).reshape(self.weight.shape)\n",
    "                self.bias -= lr * direction\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {mean_loss/(10 * len(X))}')\n",
    "                mean_loss = 0\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        mean_loss = 0\n",
    "        for index in range(len(X)):\n",
    "            x_value, y_value = X[index], y[index]\n",
    "            loss = self.__loss_fn(self.predict(x_value), y_value) \n",
    "            mean_loss += np.sqrt(loss)\n",
    "        return mean_loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c04f992-d818-4e8e-9835-747ffca0b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = LinearRegression_numpy(13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07f3e88c-e0fd-417d-af84-1682813676a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: [129.2189948]\n",
      "Epoch 10, Loss: [129.88233118]\n",
      "Epoch 20, Loss: [95.35900108]\n",
      "Epoch 30, Loss: [80.96791143]\n",
      "Epoch 40, Loss: [71.35603385]\n",
      "Epoch 50, Loss: [64.4009571]\n",
      "Epoch 60, Loss: [59.30202126]\n",
      "Epoch 70, Loss: [55.55420191]\n",
      "Epoch 80, Loss: [52.79404142]\n",
      "Epoch 90, Loss: [50.75472819]\n"
     ]
    }
   ],
   "source": [
    "w.fit(X, y, 100, 5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86df525a-b830-42de-8ac7-8e462a084e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.24965349])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28752fc-45b1-40e7-8acb-258664ea2efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09839532],\n",
       "       [ 0.06714408],\n",
       "       [ 0.7016684 ],\n",
       "       [ 0.81581469],\n",
       "       [ 0.60812591],\n",
       "       [ 0.30219948],\n",
       "       [-0.02392468],\n",
       "       [ 0.24983972],\n",
       "       [ 0.83417849],\n",
       "       [ 0.00603077],\n",
       "       [ 0.08742688],\n",
       "       [ 0.05724049],\n",
       "       [-0.09455959]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
